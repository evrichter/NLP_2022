{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEWkVBiTJ5I2"
   },
   "source": [
    "# Text Normalization\n",
    "\n",
    "As we have seen, Text Normalization is the first step before almost any natural language processing of a text. Depending on the task ahead, it usually consists of a cleaning pipeline following roughly these steps:\n",
    "\n",
    "1. Tokenization\n",
    "2. Case Folding\n",
    "3. Punctuation Removal\n",
    "4. Stopwords Removal\n",
    "5. Stemming/Lemmatization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKu3QnikLy_O"
   },
   "source": [
    "Your task is to create a function that takes as an input a text and if you want to apply stemming or lemmatization. The function should return the clean tokens, after having applied the complete cleaning pipeline.\n",
    "\n",
    "You can define several functions that perform single-purpose tasks. One function for tokenization, one for case folding, one for punctuation removal... and so on. Ideally, the function need to be defined in a separate cleaning_functions.py file and should be called from this main file.\n",
    "\n",
    "**Your deliverable is the cleaning_functions.py.**\n",
    "\n",
    "For this, you will need to know:\n",
    "* [How to mount your Google Drive in Google Colab](https://stackoverflow.com/questions/48376580/google-colab-how-to-read-data-from-my-google-drive)\n",
    "* [How to import functions from another file](https://www.geeksforgeeks.org/python-call-function-from-another-file/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1643099719678,
     "user": {
      "displayName": "ONA DE GIBERT BONET",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgTcOm2_dMJkA4Ry_ge0oD8g_mtotYKYNPg66gN=s64",
      "userId": "03677606584104604140"
     },
     "user_tz": -60
    },
    "id": "WARz1gz1ySDQ"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(1, 'home/eva/Downloads: cleaning_functions.py') # Insert folder path to be able to call file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1390,
     "status": "ok",
     "timestamp": 1643099722224,
     "user": {
      "displayName": "ONA DE GIBERT BONET",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgTcOm2_dMJkA4Ry_ge0oD8g_mtotYKYNPg66gN=s64",
      "userId": "03677606584104604140"
     },
     "user_tz": -60
    },
    "id": "Gxq6U0OAWsBt",
    "outputId": "9e294aae-69a6-460d-9c90-7be33220cfc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/eva/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/eva/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/eva/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  you will need to install your packages to the virtual machine every time you run it.\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 321,
     "status": "ok",
     "timestamp": 1643099753552,
     "user": {
      "displayName": "ONA DE GIBERT BONET",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgTcOm2_dMJkA4Ry_ge0oD8g_mtotYKYNPg66gN=s64",
      "userId": "03677606584104604140"
     },
     "user_tz": -60
    },
    "id": "euLb_A8tSNec"
   },
   "outputs": [],
   "source": [
    "from cleaning_functions  import *\n",
    "\n",
    "sentence = \"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1643099757399,
     "user": {
      "displayName": "ONA DE GIBERT BONET",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgTcOm2_dMJkA4Ry_ge0oD8g_mtotYKYNPg66gN=s64",
      "userId": "03677606584104604140"
     },
     "user_tz": -60
    },
    "id": "TAESAt8gYGy1",
    "outputId": "da954dbd-555b-4787-aa96-7dde0033addb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['truth',\n",
       " 'univers',\n",
       " 'acknowledg',\n",
       " 'singl',\n",
       " 'man',\n",
       " 'possess',\n",
       " 'good',\n",
       " 'fortun',\n",
       " 'must',\n",
       " 'want',\n",
       " 'wife']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(sentence,\"stemming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1643099761819,
     "user": {
      "displayName": "ONA DE GIBERT BONET",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgTcOm2_dMJkA4Ry_ge0oD8g_mtotYKYNPg66gN=s64",
      "userId": "03677606584104604140"
     },
     "user_tz": -60
    },
    "id": "63crA5HuYJ_w",
    "outputId": "fb951381-e18c-48a7-9557-61b47f2007ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['truth',\n",
       " 'universally',\n",
       " 'acknowledged',\n",
       " 'single',\n",
       " 'man',\n",
       " 'possession',\n",
       " 'good',\n",
       " 'fortune',\n",
       " 'must',\n",
       " 'want',\n",
       " 'wife']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(sentence,\"lemmatization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMywYGXtuK6Li1/l/Ap3AgU",
   "collapsed_sections": [],
   "mount_file_id": "1chw04S1ZqGyvA1Yeoq_XObOoXmyP0LDa",
   "name": "P3_Text_Normalization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
